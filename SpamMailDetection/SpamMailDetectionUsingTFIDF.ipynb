{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "major-strategy",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/priya/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import re\n",
    "# Tutorial about Python regular expressions: https://pymotw.com/2/re/\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import os\n",
    "\n",
    "#Metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score,classification_report\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemma = WordNetLemmatizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sized-blocking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>605</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\r\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2349</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\r\\n( see...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3624</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: neon retreat\\r\\nho ho ho , we ' re ar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4685</td>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2030</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: re : indian springs\\r\\nthis deal is t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 label                                               text  \\\n",
       "0         605   ham  Subject: enron methanol ; meter # : 988291\\r\\n...   \n",
       "1        2349   ham  Subject: hpl nom for january 9 , 2001\\r\\n( see...   \n",
       "2        3624   ham  Subject: neon retreat\\r\\nho ho ho , we ' re ar...   \n",
       "3        4685  spam  Subject: photoshop , windows , office . cheap ...   \n",
       "4        2030   ham  Subject: re : indian springs\\r\\nthis deal is t...   \n",
       "\n",
       "   label_num  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          1  \n",
       "4          0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = pd.read_csv(\"/Users/priya/Desktop/MYLAPIDOCS/Tech/KrishNaik/SpamMailDetection/spam_ham_dataset.csv\")\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "pointed-hierarchy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\r\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\r\\n( see...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: neon retreat\\r\\nho ho ho , we ' re ar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: re : indian springs\\r\\nthis deal is t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label_num\n",
       "0  Subject: enron methanol ; meter # : 988291\\r\\n...          0\n",
       "1  Subject: hpl nom for january 9 , 2001\\r\\n( see...          0\n",
       "2  Subject: neon retreat\\r\\nho ho ho , we ' re ar...          0\n",
       "3  Subject: photoshop , windows , office . cheap ...          1\n",
       "4  Subject: re : indian springs\\r\\nthis deal is t...          0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = messages.iloc[:,2:]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "characteristic-brazil",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text         0\n",
       "label_num    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "referenced-wireless",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3672\n",
       "1    1499\n",
       "Name: label_num, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label_num.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "running-sally",
   "metadata": {},
   "source": [
    "so ham = 3672\n",
    "spam = 1499"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "operating-isaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_stopwords = set([word.replace(\"'\",'') for word in stopwords.words('english')])\n",
    "\n",
    "def preprocess_text(text):\n",
    "    #text = re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", text)\n",
    "    #text = text.lower()\n",
    "    text = re.sub('[^a-zA-Z]',' ',str(text))\n",
    "    text = text.replace(\"'\",'')\n",
    "    text = text.lower()\n",
    "    words = text.split()\n",
    "    words = [lemma.lemmatize(word) for word in words if (word not in total_stopwords) and (len(word)>1)] # Remove stop words\n",
    "    text = \" \".join(words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "finished-midwest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    subject enron methanol meter follow note gave ...\n",
       "1    subject hpl nom january see attached file hpln...\n",
       "2    subject neon retreat ho ho ho around wonderful...\n",
       "3    subject photoshop window office cheap main tre...\n",
       "4    subject indian spring deal book teco pvr reven...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df['text'].apply(preprocess_text)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "legitimate-nightlife",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5171,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "exclusive-sierra",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    1\n",
       "4    0\n",
       "Name: label_num, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['label_num']\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "attempted-layer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the TF-IDF model\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tf = TfidfVectorizer()\n",
    "X = tf.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fatal-curve",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "modern-island",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test-train split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y, test_size=0.20, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "facial-artist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[719  16]\n",
      " [  1 299]]\n",
      "\n",
      "\n",
      "Training Accuracy is  99.52 %\n",
      "Testing Accuracy is  98.36 %\n",
      "Precision is  0.98\n",
      "Recall is  0.98\n",
      "CLASSIFICATION REPORT:\n",
      "                    0           1  accuracy    macro avg  weighted avg\n",
      "precision    0.998611    0.949206  0.983575     0.973909      0.984291\n",
      "recall       0.978231    0.996667  0.983575     0.987449      0.983575\n",
      "f1-score     0.988316    0.972358  0.983575     0.980337      0.983691\n",
      "support    735.000000  300.000000  0.983575  1035.000000   1035.000000\n"
     ]
    }
   ],
   "source": [
    "#logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(x_train,y_train)\n",
    "\n",
    "#predicting train set results\n",
    "y_trainpred = lr.predict(x_train)\n",
    "# Predicting the Test set results\n",
    "y_pred = lr.predict(x_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print (\"Confusion Matrix:\\n\",cm)\n",
    "\n",
    "# Accuracy, Precision and Recall\n",
    "clf_report = pd.DataFrame(classification_report(y_test, y_pred, output_dict=True))\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "score = accuracy_score(y_train,y_trainpred)\n",
    "score1 = accuracy_score(y_test,y_pred)\n",
    "score2 = precision_score(y_test,y_pred,average='micro')\n",
    "score3= recall_score(y_test,y_pred,average='micro')\n",
    "print(\"\\n\")\n",
    "print(\"Training Accuracy is \",round(score*100,2),\"%\")\n",
    "print(\"Testing Accuracy is \",round(score1*100,2),\"%\")\n",
    "print(\"Precision is \",round(score2,2))\n",
    "print(\"Recall is \",round(score3,2))\n",
    "print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "everyday-penalty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[725  10]\n",
      " [  3 297]]\n",
      "\n",
      "\n",
      "Training Accuracy is  99.93 %\n",
      "Testing Accuracy is  98.74 %\n",
      "Precision is  0.99\n",
      "Recall is  0.99\n",
      "CLASSIFICATION REPORT:\n",
      "                    0           1  accuracy    macro avg  weighted avg\n",
      "precision    0.995879    0.967427   0.98744     0.981653      0.987632\n",
      "recall       0.986395    0.990000   0.98744     0.988197      0.987440\n",
      "f1-score     0.991114    0.978583   0.98744     0.984849      0.987482\n",
      "support    735.000000  300.000000   0.98744  1035.000000   1035.000000\n"
     ]
    }
   ],
   "source": [
    "#SVM model\n",
    "from sklearn.svm import SVC\n",
    "svm= SVC(kernel='linear')\n",
    "svm.fit(x_train,y_train)\n",
    "\n",
    "\n",
    "#predicting train set results\n",
    "y_trainpred = svm.predict(x_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = svm.predict(x_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print (\"Confusion Matrix:\\n\",cm)\n",
    "\n",
    "# Accuracy, Precision and Recall\n",
    "clf_report = pd.DataFrame(classification_report(y_test, y_pred, output_dict=True))\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "score = accuracy_score(y_train,y_trainpred)\n",
    "score1 = accuracy_score(y_test,y_pred)\n",
    "score2 = precision_score(y_test,y_pred,average='micro')\n",
    "score3= recall_score(y_test,y_pred,average='micro')\n",
    "print(\"\\n\")\n",
    "print(\"Training Accuracy is \",round(score*100,2),\"%\")\n",
    "print(\"Testing Accuracy is \",round(score1*100,2),\"%\")\n",
    "print(\"Precision is \",round(score2,2))\n",
    "print(\"Recall is \",round(score3,2))\n",
    "print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "accomplished-legend",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[718  17]\n",
      " [124 176]]\n",
      "\n",
      "\n",
      "Training Accuracy is  88.32 %\n",
      "Testing Accuracy is  86.38 %\n",
      "Precision is  0.86\n",
      "Recall is  0.86\n",
      "CLASSIFICATION REPORT:\n",
      "                    0           1  accuracy    macro avg  weighted avg\n",
      "precision    0.852732    0.911917  0.863768     0.882324      0.869887\n",
      "recall       0.976871    0.586667  0.863768     0.781769      0.863768\n",
      "f1-score     0.910590    0.713996  0.863768     0.812293      0.853606\n",
      "support    735.000000  300.000000  0.863768  1035.000000   1035.000000\n"
     ]
    }
   ],
   "source": [
    "# Bernoulli NB\n",
    "\n",
    "# Fitting Naive Bayes to the Training set\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "classifier = BernoulliNB(alpha=0.8)\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "#predicting train set results\n",
    "y_trainpred = classifier.predict(x_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(x_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print (\"Confusion Matrix:\\n\",cm)\n",
    "\n",
    "# Accuracy, Precision and Recall\n",
    "clf_report = pd.DataFrame(classification_report(y_test, y_pred, output_dict=True))\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "score = accuracy_score(y_train,y_trainpred)\n",
    "score1 = accuracy_score(y_test,y_pred)\n",
    "score2 = precision_score(y_test,y_pred,average='micro')\n",
    "score3= recall_score(y_test,y_pred,average='micro')\n",
    "print(\"\\n\")\n",
    "print(\"Training Accuracy is \",round(score*100,2),\"%\")\n",
    "print(\"Testing Accuracy is \",round(score1*100,2),\"%\")\n",
    "print(\"Precision is \",round(score2,2))\n",
    "print(\"Recall is \",round(score3,2))\n",
    "print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governing-jumping",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
